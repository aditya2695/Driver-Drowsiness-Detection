{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from customDataset import DrowsyDataset as DD\n",
    "from customModel import CustomCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transforms to be applied on the images\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2320\n",
      "Test set size: 580\n"
     ]
    }
   ],
   "source": [
    "# Create instances of the custom dataset class for train, validation and test data\n",
    "dataset = DD('data/train/', data_transforms)\n",
    "\n",
    "# # Get the labels from the dataset\n",
    "# labels = np.array([label for _, label in dataset])\n",
    "\n",
    "# Split the dataset into train and test sets, stratified by the target variable\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2,  random_state=42)\n",
    "\n",
    "# Print the sizes of train and test sets\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Test set size:\", len(test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size for DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AlexNet(\n",
       "   (features): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "     (4): ReLU(inplace=True)\n",
       "     (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (7): ReLU(inplace=True)\n",
       "     (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (9): ReLU(inplace=True)\n",
       "     (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (11): ReLU(inplace=True)\n",
       "     (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "   (classifier): Sequential(\n",
       "     (0): Dropout(p=0.5, inplace=False)\n",
       "     (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "     (3): Dropout(p=0.5, inplace=False)\n",
       "     (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "     (5): ReLU(inplace=True)\n",
       "     (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "   )\n",
       " ),\n",
       " CustomCNN(\n",
       "   (features): Sequential(\n",
       "     (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (4): ReLU(inplace=True)\n",
       "     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=100352, out_features=256, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Find model files in the models directory\n",
    "model_dir = 'models'\n",
    "model_paths = [os.path.join(model_dir, file) for file in os.listdir(model_dir) if file.endswith('.pth')]\n",
    "\n",
    "# Load the models\n",
    "models = []\n",
    "for model_path in model_paths:\n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize lists to store the predicted labels and true labels\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over the test dataset and make predictions with each model\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Initialize lists to store predictions from each model\n",
    "    model_predictions = []\n",
    "    \n",
    "    # Make predictions with each model\n",
    "    for model in models:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        model_predictions.append(predicted.cpu().numpy())\n",
    "    \n",
    "    # Compute average ensemble predictions\n",
    "    ensemble_predictions = sum(model_predictions) / len(models)\n",
    "    \n",
    "    # Append the ensemble predictions and true labels to the lists\n",
    "    predicted_labels.extend(ensemble_predictions)\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.907\n",
      "Precision: 0.918\n",
      "Recall: 0.907\n",
      "F1 Score: 0.907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "#  Compute the test metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Print the test metrics\n",
    "print(\"Accuracy:\", round(accuracy,3))\n",
    "print(\"Precision:\", round(precision,3))\n",
    "print(\"Recall:\", round(recall,3))\n",
    "print(\"F1 Score:\", round(f1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
